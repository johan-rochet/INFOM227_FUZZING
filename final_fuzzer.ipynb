{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzingbook.Grammars import Grammar, Expansion, srange\n",
    "\n",
    "from fuzzingbook.GrammarFuzzer import GrammarFuzzer\n",
    "from isla.solver import ISLaSolver, SemanticError\n",
    "from fuzzingbook.Parser import EarleyParser\n",
    "from fuzzingbook.MutationFuzzer import FunctionCoverageRunner\n",
    "from fuzzingbook.GreyboxGrammarFuzzer import  FragmentMutator, PowerSchedule, LangFuzzer, SeedWithStructure\n",
    "from fuzzingbook.Coverage import population_coverage\n",
    "from fuzzingbook.GrammarCoverageFuzzer import GrammarCoverageFuzzer, extend_grammar, duplicate_context\n",
    "from fuzzingbook.GreyboxFuzzer import Seed\n",
    "import time\n",
    "from typing import List\n",
    "import string\n",
    "import csv\n",
    "from pandas.errors import ParserError, EmptyDataError\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ordered_set import OrderedSet\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ascii_printable = list(string.printable)\n",
    "list_ascii_printable.remove('\"')\n",
    "list_ascii_printable.remove(\"\\r\")\n",
    "list_ascii_printable.remove(\"\\n\")\n",
    "list_ascii_printable.remove(\",\")\n",
    "\n",
    "list_char: List[Expansion] = srange(\"\".join(list_ascii_printable))\n",
    "\n",
    "CSV_GRAMMMAR: Grammar = {\n",
    "    \"<start>\": [\"<csv-file>\"],\n",
    "    \"<csv-file>\": [\"<hdr>\", \"<rows>\"],\n",
    "    \"<rows>\": [\"<row>\", \"<row><crlf><rows>\", \"<row><crlf>\"],\n",
    "    \"<hdr>\": [\"<row>\"],\n",
    "    \"<row>\" : [\"<fields>\"],\n",
    "    \"<fields>\": [\"<field>\", \"<field><comma><fields>\"],\n",
    "    \"<field>\": [\"<TEXT>\", \"<STRING>\", \"\"],\n",
    "    \"<TEXT>\": [\"<character>\", \"<character><TEXT>\"],\n",
    "    \"<STRING>\": [\"<dblquote><list_character><dblquote>\", \"<dblquote><dblquote>\"],\n",
    "    \"<list_character>\": [\n",
    "        \"<character>\",\n",
    "        \"<character><list_character>\",\n",
    "        \"<dblquote><dblquote><list_character>\",\n",
    "    ],\n",
    "    \"<character>\": list_char,\n",
    "    \"<dblquote>\": [chr(34)],\n",
    "    \"<comma>\": [\",\"],\n",
    "    \"<crlf>\": [\"\\r\\n\"],\n",
    "}\n",
    "START_SYMBOL = \"<start>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_CSV_GRAMMMAR = extend_grammar(CSV_GRAMMMAR)\n",
    "\n",
    "duplicate_context(dup_CSV_GRAMMMAR, \"<rows>\", \"<row><rows>\")\n",
    "duplicate_context(dup_CSV_GRAMMMAR, \"<rows>\", \"<row><crlf><rows>\")\n",
    "duplicate_context(dup_CSV_GRAMMMAR, \"<fields>\", \"<field><comma><fields>\")\n",
    "duplicate_context(dup_CSV_GRAMMMAR, \"<TEXT>\", \"<character><TEXT>\")\n",
    "duplicate_context(dup_CSV_GRAMMMAR, \"<list_character>\", \"<character><list_character>\")\n",
    "duplicate_context(dup_CSV_GRAMMMAR, \"<STRING>\", \"<dblquote><dblquote><list_character>\")\n",
    "\n",
    "dup_gram_cov_fuzzer: GrammarCoverageFuzzer = GrammarCoverageFuzzer(dup_CSV_GRAMMMAR, start_symbol=START_SYMBOL, max_nonterminals= 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = ISLaSolver(CSV_GRAMMMAR, # type: ignore\n",
    "                    '''    \n",
    "                    exists int nb_comma :\n",
    "                        exists <row> r : \n",
    "                            (count(r, \"<comma>\", nb_comma)\n",
    "                            and \n",
    "                            forall <row> row in <rows>:\n",
    "                                count(row, \"<comma>\", nb_comma))\n",
    "                    '''\n",
    "                    )       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: generate valid seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds: list[SeedWithStructure] = []\n",
    "syntax_erroneous_inputs = []\n",
    "semantic_erroneous_inputs = []\n",
    "def parse_input(input: str)  -> str:\n",
    "    f = open(\"test.csv\", \"w\")\n",
    "    f.write(input)\n",
    "    f.close()\n",
    "    with open(\"test.csv\", newline=\"\") as f:\n",
    "        csv.reader(f)\n",
    "\n",
    "    pd.read_csv(\"test.csv\", delimiter=\",\", engine=\"python\")\n",
    "    \n",
    "    return input\n",
    "\n",
    "def fuzz_for_seeds(fuzzer: GrammarFuzzer) :\n",
    "    \n",
    "    fuzz = fuzzer.fuzz()\n",
    "\n",
    "    try : \n",
    "        solver.parse(fuzz, silent=True)\n",
    "    except SyntaxError as e:\n",
    "        syntax_erroneous_inputs .append(fuzz)\n",
    "    \n",
    "    except SemanticError as e:\n",
    "        semantic_erroneous_inputs.append(fuzz)\n",
    "    else :  \n",
    "        seeds.append(SeedWithStructure(fuzz))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5127/5127 [05:30<00:00, 15.50it/s] \n"
     ]
    }
   ],
   "source": [
    "seeds: list[SeedWithStructure] = []\n",
    "open(\"tests.log\", \"w\").close()\n",
    "total_coverage = len(dup_gram_cov_fuzzer.max_expansion_coverage())\n",
    "coverage = 0\n",
    "for i in tqdm(range(total_coverage)):\n",
    "    while coverage == i :\n",
    "        fuzz_for_seeds(dup_gram_cov_fuzzer)\n",
    "        coverage = total_coverage - len(dup_gram_cov_fuzzer.max_expansion_coverage() - dup_gram_cov_fuzzer.expansion_coverage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635 valid seeds created\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"%d valid seeds created\" % len(seeds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 : Generate fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=1000\n",
    "runner = FunctionCoverageRunner(parse_input)\n",
    "parser = EarleyParser(CSV_GRAMMMAR)\n",
    "mutator = FragmentMutator(parser)\n",
    "schedule = PowerSchedule()\n",
    "\n",
    "\n",
    "\n",
    "lang_fuzzer = LangFuzzer([seed.data for seed in seeds], mutator, schedule)\n",
    "\n",
    "start = time.time()\n",
    "lang_fuzzer.runs(runner, trials=n)\n",
    "end = time.time()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From the 846 different generated inputs, 824 (97.40%) can be parsed.\n",
      "In total, 1632 statements are covered.\n"
     ]
    }
   ],
   "source": [
    "# Ordered set to avoid duplicates for later performance\n",
    "syntax_error = OrderedSet([])\n",
    "semantic_error = OrderedSet([])\n",
    "other_error = OrderedSet([])\n",
    "parsed_inputs = OrderedSet([])\n",
    "\n",
    "def sort_seed(seed: Seed) -> int:\n",
    "    try:\n",
    "        solver.parse(seed.data, silent=True)\n",
    "        \n",
    "        \n",
    "    except SyntaxError:\n",
    "        syntax_error.add(seed.data)\n",
    "        return 0\n",
    "    except SemanticError:\n",
    "        semantic_error.add(seed.data)\n",
    "        return 0\n",
    "    except Exception:\n",
    "        other_error.add(seed.data)\n",
    "        return 0\n",
    "    else: \n",
    "        parsed_inputs.add(seed.data)\n",
    "        return 1\n",
    "    \n",
    "    \n",
    "\n",
    "coverage, _ = population_coverage(lang_fuzzer.inputs, parse_input)\n",
    "\n",
    "for seed in lang_fuzzer.inputs:\n",
    "    # reuse memoized information\n",
    "    if hasattr(seed, \"has_structure\"):\n",
    "        \n",
    "         sort_seed(seed)  # type: ignore\n",
    "    else:\n",
    "        if isinstance(seed, str):\n",
    "            seed = Seed(seed)\n",
    "        sort_seed(seed) \n",
    "\n",
    "total_inputs = (len(parsed_inputs)+len(syntax_error)+len(semantic_error)+len(other_error))\n",
    "\n",
    "print(\"From the %d different generated inputs, %d (%0.2f%%) can be parsed.\\n\"\n",
    "        \"In total, %d statements are covered.\" % (\n",
    "        total_inputs,\n",
    "        len(parsed_inputs),\n",
    "        100 * len(parsed_inputs) / total_inputs,\n",
    "        len(coverage)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lang fuzzer generated :\n",
      "-----------------------------\n",
      "# Correct inputs: 824\n",
      "# Invalid syntax inputs: 17\n",
      "# Invalid semantic inputs: 5\n",
      "# Other errors inputs: 0\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"The lang fuzzer generated :\")\n",
    "print(\"-----------------------------\")\n",
    "print(\"# Correct inputs: %d\" % len(parsed_inputs))\n",
    "\n",
    "print(\"# Invalid syntax inputs: %d\" % len(syntax_error))\n",
    "\n",
    "print(\"# Invalid semantic inputs: %d\" % len(semantic_error))\n",
    "\n",
    "print(\"# Other errors inputs: %d\" % len(other_error))\n",
    "print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 : Check inputs on the target function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wrongly_parsed_inputs = []\n",
    "wrongly_parsed_inputs_syntax = []\n",
    "wrongly_parsed_inputs_semantic = []\n",
    "wrongly_parsed_inputs_other = []\n",
    "\n",
    "def check_correct_input(input : str) -> None :\n",
    "    try : \n",
    "        parse_input(input)\n",
    "    except Exception as e:\n",
    "        wrongly_parsed_inputs.append(input)\n",
    "\n",
    "\n",
    "\n",
    "def check_semantic_incorrect_input(input : str) -> None :\n",
    "    try : \n",
    "        parse_input(input)\n",
    "        wrongly_parsed_inputs_semantic.append(input)\n",
    "        \n",
    "    except (ParserError , EmptyDataError) :\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        wrongly_parsed_inputs_semantic.append(input)\n",
    "\n",
    "def check_syntax_incorrect_input(input : str) -> None :\n",
    "    try : \n",
    "        parse_input(input)\n",
    "        wrongly_parsed_inputs_syntax.append(input)\n",
    "        \n",
    "    except (ParserError , EmptyDataError) :\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        wrongly_parsed_inputs_other.append(input)\n",
    "\n",
    "def check_other_incorrect_input(input : str) -> None :\n",
    "\n",
    "    try : \n",
    "        parse_input(input)\n",
    "        wrongly_parsed_inputs_other.append(input)\n",
    "        \n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for correct_input in parsed_inputs:\n",
    "    check_correct_input(correct_input)\n",
    "\n",
    "for syntax_error_input in syntax_error:\n",
    "    check_syntax_incorrect_input(syntax_error_input)\n",
    "\n",
    "for semantic_error_input in semantic_error:\n",
    "    check_semantic_incorrect_input(semantic_error_input)\n",
    "\n",
    "for other_error_input in other_error:\n",
    "    check_other_incorrect_input(other_error_input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly handled inputs :\n",
      "-----------------------------\n",
      "# wrongly handled inputs: 13\n",
      "['\\r\\n', '\"\"', '\\x0c', '\\t', '\\x0b\\r\\n', ' \\r\\n', '', '\\r\\n\"\"', '\"\"\\r\\n', '\"\\x0b\"\\r\\n', '\"\\x0b\"', '\\r\\n\\r\\n', '\\r\\n\"\"\\r\\n']\n",
      "-------\n",
      "# wrongly handled syntaxically wrong inputs: 6\n",
      "[')=[\",\"\\x0b\"', 'h1XU\"\\r\\n', '\\r\\nD:\"\\r\\n', '>- \"', '6\\x0c\"\\r\\n', '.:\\\\}\"\\r\\n']\n",
      "-------\n",
      "# wrongly handled semantically wrong inputs: 5\n",
      "['\"#\"\\r\\n\"3[&X(\",\"&X[&X(\"\\r\\n', '\"E4z\"\\r\\n$%y,nb, ', '$%y,nb,&\\r\\n\\r\\n', '+\\r\\n\"\\x0bjX(\",\"_qT\"', 'H\\r\\n3,Z8z']\n",
      "-------\n",
      "# wrongly handled other wrong inputs: 0\n",
      "[]\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Correctly handled inputs :\")\n",
    "print(\"-----------------------------\")\n",
    "print(\"# wrongly handled inputs: %d\" % len(wrongly_parsed_inputs))\n",
    "print(wrongly_parsed_inputs)\n",
    "print(\"-------\")\n",
    "print(\"# wrongly handled syntaxically wrong inputs: %d\" % len(wrongly_parsed_inputs_syntax))\n",
    "print(wrongly_parsed_inputs_syntax)\n",
    "print(\"-------\")\n",
    "print(\"# wrongly handled semantically wrong inputs: %d\" % len(wrongly_parsed_inputs_semantic))\n",
    "print(wrongly_parsed_inputs_semantic)\n",
    "print(\"-------\")\n",
    "print(\"# wrongly handled other wrong inputs: %d\" % len(wrongly_parsed_inputs_other))\n",
    "print(wrongly_parsed_inputs_other)\n",
    "print(\"-----------------------------\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
